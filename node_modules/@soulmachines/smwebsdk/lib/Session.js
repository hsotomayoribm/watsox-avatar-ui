"use strict";
/**
 * @module smwebsdk
 */
Object.defineProperty(exports, "__esModule", { value: true });
exports.Session = exports.UserMedia = void 0;
var tslib_1 = require("tslib");
/*
 * Copyright 2017-2020 Soul Machines Ltd. All Rights Reserved.
 */
var Deferred_1 = require("./Deferred");
var Features_1 = require("./Features");
var scene_1 = require("./types/scene");
var make_error_1 = require("./utils/make-error");
var ConnectionStateTypes_1 = require("./enums/ConnectionStateTypes");
// Reexporting here to keep backwards compatibility
var scene_2 = require("./types/scene");
Object.defineProperty(exports, "UserMedia", { enumerable: true, get: function () { return scene_2.UserMedia; } });
/**
 *  Session class
 */
var Session = /** @class */ (function () {
    function Session(videoElement, serverUri, connectUserText, accessToken, audioOnly, requestedUserMedia, requiredUserMedia, echoCancellationEnabled, logger, connectionState) {
        var _this = this;
        // eslint-disable-next-line @typescript-eslint/ban-types
        this._connectPendingRemoteStream = null;
        this._resumeRequested = false;
        this._isResumedSession = false;
        this._outgoingQueue = [];
        this._controlOpen = false;
        this._controlQueue = [];
        this._requestedUserMedia = scene_1.UserMedia.None;
        this._requiredUserMedia = scene_1.UserMedia.None;
        this._onConnected = function (resumeRequested, isResumedSession, server, sessionId
        // eslint-disable-next-line @typescript-eslint/no-empty-function
        ) { };
        this._pendingLog = [];
        this._closed = false;
        this._shouldLogToServer = false;
        // Duration that microphone mute is maintained by the web sdk after the persona has
        // finished speaking.  Set to -1 to disable.  Default value is -1 (disabled) if not specified
        // by server in 'established' message.
        this._microphoneMuteDelay = -1;
        this._changeUserMediaQueue = new Array();
        this._removeListeners = new Array();
        this._videoOptions = {
            frameRate: 10.0,
            width: 640.0,
            height: 480.0,
            facingMode: 'user',
        };
        // TypeScript support to MediaTrackConstraints is not complete, thus using any here
        this._audioOptions = {
            noiseSuppression: false,
            autoGainControl: false,
            channelCount: 1,
            sampleRate: 16000,
            sampleSize: 16,
            echoCancellation: true,
        };
        this._videoElement = videoElement;
        this._serverUri = serverUri;
        this._connectUserText = connectUserText || '';
        this._accessToken = accessToken;
        this._audioOnly = audioOnly;
        this._audioOptions.echoCancellation = echoCancellationEnabled;
        this._requiredUserMedia = requiredUserMedia;
        this._requestedUserMedia = requestedUserMedia;
        this._logger = logger;
        // eslint-disable-next-line @typescript-eslint/no-empty-function
        this._onClose = function (reason) { }; // owner specifies custom close method
        // eslint-disable-next-line @typescript-eslint/no-empty-function
        this._onMessage = function (message) { }; // owner specifies custom message handler
        // eslint-disable-next-line @typescript-eslint/no-empty-function
        this._onUserText = function (text) { }; // owner specifies custom rtc user text message handler
        this._sessionError = function (error) {
            // owner can specify custom session error handler
            _this.log("session error: ".concat(error), 'error');
        };
        this._features = new Features_1.Features();
        this._connectionState = connectionState;
    }
    Object.defineProperty(Session.prototype, "onConnected", {
        set: function (sessionFunction) {
            this._onConnected = sessionFunction;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Session.prototype, "onClose", {
        set: function (closeFunction) {
            this._onClose = closeFunction;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Session.prototype, "onMessage", {
        set: function (messageFunction) {
            this._onMessage = messageFunction;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Session.prototype, "onUserText", {
        set: function (userTextFunction) {
            this._onUserText = userTextFunction;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Session.prototype, "loggingEnabled", {
        /**
         * @deprecated use Scene method
         */
        get: function () {
            return this._logger.isEnabled;
        },
        /**
         * @deprecated use Scene
         */
        set: function (enable) {
            this.log('loggingEnabled is deprecated and will be removed in a future version. Please use setLogging(boolean)', 'warn');
            this._logger.enableLogging(enable);
        },
        enumerable: false,
        configurable: true
    });
    /**
     * @deprecated use Scene method
     */
    Session.prototype.setMinLogLevel = function (level) {
        this._logger.setMinLogLevel(level);
    };
    /**
     * @deprecated use Scene method
     */
    Session.prototype.setLogging = function (enable) {
        this._logger.enableLogging(enable);
    };
    Session.prototype.log = function (text, level) {
        if (level === void 0) { level = 'debug'; }
        if (this._logger.isEnabled) {
            var now = new Date();
            var msg = "smsdk: ".concat(now.toISOString(), ": ").concat(text);
            if (this._shouldLogToServer) {
                this.logToServer(msg);
            }
            this._logger.log(level, msg);
        }
    };
    Session.prototype.logToServer = function (msg) {
        if (this.sessionId) {
            this.sendlogMessage([msg]);
        }
        else {
            this._pendingLog.push(msg);
        }
    };
    Session.prototype.sendlogMessage = function (textArray) {
        if (this._sessionId && textArray && textArray.length > 0) {
            var payload = {
                category: 'diagnostics',
                kind: 'event',
                name: 'log',
                body: { name: 'browser', text: textArray },
            };
            this.sendMessage(payload);
        }
    };
    Session.prototype.connect = function (userText) {
        return tslib_1.__awaiter(this, void 0, void 0, function () {
            var deferred, xhr;
            var _this = this;
            return tslib_1.__generator(this, function (_a) {
                deferred = new Deferred_1.Deferred();
                this._closed = false;
                if (userText) {
                    this._connectUserText = userText;
                }
                if (this._serverUri &&
                    (this._serverUri.startsWith('ws:') || this._serverUri.startsWith('wss:'))) {
                    // A server uri has been specified, continue with the connection
                    // by acquiring user media (microphone/camera) as needed
                    this.selectUserMedia(this._requestedUserMedia, this._requiredUserMedia, deferred, this.getUserMediaSuccess.bind(this));
                    return [2 /*return*/, deferred.promise];
                }
                xhr = new XMLHttpRequest();
                xhr.open('GET', '/api/jwt' + window.location.search);
                xhr.onreadystatechange = function (ev) { return tslib_1.__awaiter(_this, void 0, void 0, function () {
                    var response;
                    return tslib_1.__generator(this, function (_a) {
                        if (xhr.readyState === XMLHttpRequest.DONE) {
                            if (xhr.status === 200) {
                                this.log("JWT request returned: ".concat(xhr.responseText));
                                response = JSON.parse(xhr.responseText);
                                this._serverUri = response.url;
                                this._accessToken = response.jwt;
                                this.selectUserMedia(this._requestedUserMedia, this._requiredUserMedia, deferred, this.getUserMediaSuccess.bind(this));
                            }
                            else {
                                this.log("JWT Request failed, status: ".concat(xhr.statusText), 'error');
                                deferred.reject((0, make_error_1.makeError)('Failed to acquire jwt at /api/jwt', 'noServer'));
                            }
                        }
                        return [2 /*return*/];
                    });
                }); };
                xhr.send();
                return [2 /*return*/, deferred.promise];
            });
        });
    };
    Session.prototype.webcamRequested = function (requestedMedia, requiredMedia) {
        return (!this._audioOnly &&
            [scene_1.UserMedia.MicrophoneAndCamera, scene_1.UserMedia.Camera].some(function (r) {
                return [requestedMedia, requiredMedia].includes(r);
            }));
    };
    Session.prototype.micRequested = function (requestedMedia, requiredMedia) {
        return [scene_1.UserMedia.Microphone, scene_1.UserMedia.MicrophoneAndCamera].some(function (r) {
            return [requestedMedia, requiredMedia].includes(r);
        });
    };
    Session.prototype.getMediaConstraints = function (requestedMedia, requiredMedia) {
        // checking supported constraints only for debugging purpose, no need to use it when applying constraints
        // as providing specific values for constraints, means they are a 'best effort' rather than required
        // https://developer.mozilla.org/en-US/docs/Web/API/Media_Streams_API/Constraints#requesting_a_specific_value_for_a_setting
        var supports = navigator.mediaDevices.getSupportedConstraints();
        this.log("Browser supports media constraints: ".concat(supports));
        return {
            audio: this.micRequested(requestedMedia, requiredMedia)
                ? this.buildAudioOptions()
                : false,
            video: this.webcamRequested(requestedMedia, requiredMedia)
                ? this._videoOptions
                : false,
        };
    };
    Session.prototype.buildAudioOptions = function () {
        var supportedConstraints = navigator.mediaDevices.getSupportedConstraints();
        var constraints = tslib_1.__assign({}, this._audioOptions);
        // Remove unknown and unsupported constraints, as these were causing errors in the latest version on Safari
        Object.keys(constraints).forEach(function (constraint) {
            if (!supportedConstraints[constraint]) {
                delete constraints[constraint];
            }
        });
        return constraints;
    };
    Session.prototype.selectUserMedia = function (requestedMedia, requiredMedia, deferred, completion) {
        var _this = this;
        if (requestedMedia === scene_1.UserMedia.None && requiredMedia === scene_1.UserMedia.None) {
            // no microphone or camera is required or requested
            completion(null, deferred);
            return;
        }
        if (navigator.mediaDevices.getUserMedia) {
            var constraints = this.getMediaConstraints(requestedMedia, requiredMedia);
            this.log("Best video constraints: ".concat(constraints));
            navigator.mediaDevices
                .getUserMedia(constraints)
                .then(function (stream) {
                completion(stream, deferred);
            })
                .catch(function (error) {
                //fail when required media wasn't obtained
                if (requiredMedia === requestedMedia) {
                    _this.log("getUserMedia could not get required media, error given: ".concat(error), 'error');
                    deferred.reject(_this.MakeErrorForUserMedia(error));
                }
                //re-try required media fallback
                else if (requiredMedia !== scene_1.UserMedia.None) {
                    _this.getUserMediaRequiredOnlyFallback(requiredMedia, deferred, completion);
                }
                //re-try mic only fallback
                else if (requestedMedia === scene_1.UserMedia.MicrophoneAndCamera) {
                    _this.getUserMediaAudioOnlyFallback(deferred, completion);
                }
                //complete without a stream
                else {
                    completion(null, deferred);
                }
            });
        }
        else {
            deferred.reject((0, make_error_1.makeError)('Your browser does not support getUserMedia API', 'notSupported'));
        }
    };
    Session.prototype.getUserMediaRequiredOnlyFallback = function (requiredMedia, deferred, completion) {
        var _this = this;
        this.log('Retrying with required media only');
        var constraints = this.getMediaConstraints(scene_1.UserMedia.None, requiredMedia);
        this.log("Attempt constraints: ".concat(constraints));
        return navigator.mediaDevices
            .getUserMedia(constraints)
            .then(function (stream) {
            completion(stream, deferred);
        })
            .catch(function (error) {
            _this.log("getUserMedia could not get required media, error given: ".concat(error), 'error');
            //fail when required media wasn't obtained
            deferred.reject(_this.MakeErrorForUserMedia(error));
        });
    };
    Session.prototype.getUserMediaAudioOnlyFallback = function (deferred, completion) {
        var _this = this;
        this.log('Retrying with microphone only');
        var constraints = {
            video: false,
            audio: this.buildAudioOptions(),
        };
        this.log("Attempt constraints: ".concat(constraints));
        return navigator.mediaDevices
            .getUserMedia(constraints)
            .then(function (stream) {
            completion(stream, deferred);
        })
            .catch(function (error) {
            _this.log("getUserMedia could not get microphone audio, error given: ".concat(error), 'error');
            // still succeed as fallback is only tried if media was required, not requested
            completion(null, deferred);
        });
    };
    Session.prototype.MakeErrorForUserMedia = function (error) {
        var name = 'noUserMedia';
        // Returning more specific errors below is considered a breaking change which we
        // cannot accommodate currently. This will be reinstated in the future, likely for v15
        // At that time, the error codes in Scene.connect() and scene.setMediaDeviceActive() need re-documenting -
        // see https://github.com/soulmachines/smwebsdk/blob/dfe3e1dc8d57aac17cb0be38fa2527190cd78ef4/src/Scene.ts#L916-L918
        // if (error.name === 'NotAllowedError' || error.name === 'SecurityError') {
        //   name = 'userMediaNotAllowed';
        // } else if (
        //   error.name === 'AbortError' ||
        //   error.name === 'NotReadableError'
        // ) {
        //   name = 'userMediaFailed';
        // }
        return (0, make_error_1.makeError)(error.message, name);
    };
    Session.prototype.getUserMediaSuccess = function (stream, deferred) {
        var _this = this;
        this.log('Got user media');
        this._localStream = stream;
        this.microphoneMuted = true; // mute the local microphone until the DP is visible
        // Connect to the session server
        // To pass the Json Web Token (jwt) to the server when opening the websocket
        // we basically have three options with the available javascript api:
        // 1) pass as a 'access_token' query parameter similar to auth2 bearer tokens when not auth header
        // 2) pass as basic auth user/pass embedded in the url
        // 3) pass as a custom protocol which is translated into the 'Sec-WebSocket-Protocol' request header
        //    more info here: https://stackoverflow.com/questions/4361173/http-headers-in-websockets-client-api
        // We've gone with using a query parameter with ssl.
        // create and connect the websocket
        // Note that javscript websockets do not allow most request headers to be set.  The two exceptions
        // are the Authorization header (via basic auth) and the protocol header - neither of which
        // are ideal for our jwt token.  Hence instead we pass the jwt as a query parameter.
        this.log("connecting to: ".concat(this._serverUri));
        if (!this._accessToken) {
            this._serverConnection = new WebSocket(this._serverUri);
        }
        else {
            this._serverConnection = new WebSocket(this._serverUri + '?access_token=' + this._accessToken);
        }
        this._serverConnection.onmessage = function (msg) {
            try {
                _this.gotMessageFromServer(msg, deferred);
            }
            catch (e) {
                _this.log("unexpected exception processing received message: ".concat(e), 'error');
            }
        };
        this._serverConnection.onerror = function (event) {
            if (deferred.isPending()) {
                deferred.reject((0, make_error_1.makeError)('websocket failed', 'serverConnectionFailed'));
            }
        };
        // wait for the websocket to open, then continue with setup
        this._serverConnection.onopen = function (event) {
            _this.log('Websocket open');
            // wait for the welcome 'established' message to receive the ice servers, hence nothing more to do here
            // websocket open - searching for an available DP scene, may require queuing
            _this._connectionState.setConnectionState(ConnectionStateTypes_1.ConnectionStateTypes.SearchingForDigitalPerson);
        };
        // setup a close handler
        this._serverConnection.onclose = function (event) {
            _this.log("websocket closed: code(".concat(event.code, "), reason(").concat(event.reason, "), clean(").concat(event.wasClean, ")"));
            if (!deferred.isRejected) {
                _this.close(false, 'normal', deferred);
            }
        };
    };
    Session.prototype.hasTurnServer = function (iceServers) {
        var e_1, _a, e_2, _b;
        // Check for at least one turn server by url in the array of ice servers
        if (!iceServers) {
            return false;
        }
        try {
            for (var iceServers_1 = tslib_1.__values(iceServers), iceServers_1_1 = iceServers_1.next(); !iceServers_1_1.done; iceServers_1_1 = iceServers_1.next()) {
                var server = iceServers_1_1.value;
                if (!server || !server.urls) {
                    continue;
                }
                try {
                    for (var _c = (e_2 = void 0, tslib_1.__values(server.urls)), _d = _c.next(); !_d.done; _d = _c.next()) {
                        var url = _d.value;
                        if (url.indexOf('turn:') === 0) {
                            return true;
                        }
                    }
                }
                catch (e_2_1) { e_2 = { error: e_2_1 }; }
                finally {
                    try {
                        if (_d && !_d.done && (_b = _c.return)) _b.call(_c);
                    }
                    finally { if (e_2) throw e_2.error; }
                }
            }
        }
        catch (e_1_1) { e_1 = { error: e_1_1 }; }
        finally {
            try {
                if (iceServers_1_1 && !iceServers_1_1.done && (_a = iceServers_1.return)) _a.call(iceServers_1);
            }
            finally { if (e_1) throw e_1.error; }
        }
        return false;
    };
    Session.prototype.gotMessageFromServer = function (websocket_message, deferred) {
        var _this = this;
        var _a, _b;
        var raw_text = websocket_message.data;
        this.log("message received: ".concat(raw_text));
        var message = JSON.parse(raw_text);
        var category = message.category;
        var name = message.name;
        var body = message.body;
        if (category !== 'webrtc') {
            // If there is a control connection then forward 'scene' messages to that
            if (this._controlConnection !== null && category === 'scene') {
                if (this._controlOpen &&
                    this._serverConnection.readyState === WebSocket.OPEN) {
                    this._controlConnection.send(raw_text);
                }
                else {
                    this._controlQueue.push(raw_text);
                }
            }
            // forward on non-webrtc messages (e.g. scene)
            this._onMessage(message);
            return;
        }
        if (message.kind !== 'event') {
            // currently ignore requests and responses
            return;
        }
        if (name === 'established') {
            // established - scene is available/found, downloading/preparing DP assets on the server
            this._connectionState.setConnectionState(ConnectionStateTypes_1.ConnectionStateTypes.DownloadingAssets);
            // Create the peer connection configuration from the established body
            // which includes the ice servers we should use
            var config = { iceServers: [] };
            if (body.iceServers) {
                config.iceServers = body.iceServers;
                // If at least one ice server is a turn server then force
                // our traffic to route over turn (relay)
                if (this.hasTurnServer(body.iceServers)) {
                    this.log('Detected turn server, forcing relay mode');
                    config.iceTransportPolicy = 'relay';
                }
            }
            this.log("selected ice servers: ".concat(config.iceServers));
            if (body.settings &&
                typeof body.settings.microphoneMuteDelay === 'number') {
                this._microphoneMuteDelay = body.settings.microphoneMuteDelay;
            }
            this.log("microphone mute delay after persona speech: ".concat(this._microphoneMuteDelay));
            // Send logging to server if requested by the server
            this._shouldLogToServer = (_b = (_a = body.settings) === null || _a === void 0 ? void 0 : _a.logToServer) !== null && _b !== void 0 ? _b : false;
            // Setup the WebRTC peer connection
            this._peerConnection = new RTCPeerConnection(config);
            // ref: Ice candidate will only trigger when media video is enabled in Safari
            // https://stackoverflow.com/a/53914556
            this._peerConnection.onicecandidate = this.gotIceCandidate.bind(this);
            if ('ontrack' in this._peerConnection && !this._features.isEdge) {
                // todo update when angular 7
                // This doesnt work with angular yet because of old definitions
                // this._peerConnection.ontrack = (event:RTCTrackEvent)=>{
                this._peerConnection.ontrack = function (event) {
                    if (event.track.kind === 'video' || event.track.kind === 'audio') {
                        if (!_this._remoteStream ||
                            (!_this._audioOnly && event.track.kind === 'video')) {
                            _this.onRemoteStream(event.streams[0]);
                        }
                    }
                };
                // Attach a video loaded event so the server can be notified when the video is
                // ready to start playing
                this._videoElement.addEventListener('loadeddata', this.onVideoLoaded.bind(this));
                this._removeListeners.push({
                    target: this._videoElement,
                    name: 'loadeddata',
                    callback: this.onVideoLoaded,
                });
            }
            else {
                // fallback to stream (for IE/Safari plugin)
                // onaddstream is deprecated
                // This feature has been removed from the Web standards.
                // Though some browsers may still support it, it is in the process of being dropped.
                // Writing like this to pass type checking as this isnt in current spec and therefore
                // neither the type definitions
                this._peerConnection.onaddstream = function (
                // as any because MediaStreamEvent has been removed from lib.dom.d.ts
                streamEvent) {
                    _this.onRemoteStream(streamEvent.stream);
                };
            }
            this._peerConnection.oniceconnectionstatechange = function (e) {
                // `this._peerConnection.iceConnectionState === 'disconnected'` is quite handy
                _this.log("ICE connection state: ".concat(_this._peerConnection.iceConnectionState));
                if (_this._peerConnection.iceConnectionState === 'failed') {
                    (0, make_error_1.makeError)('ice connection failed', 'mediaStreamFailed');
                    if (deferred && deferred.isPending()) {
                        // Close the connection and reject the connect()
                        _this._serverConnection.close();
                        if (_this._controlConnection &&
                            (_this._controlConnection.readyState === WebSocket.OPEN ||
                                _this._controlConnection.readyState === WebSocket.CONNECTING)) {
                            _this._controlConnection.close();
                        }
                        deferred.reject((0, make_error_1.makeError)('ice connection failed', 'mediaStreamFailed'));
                    }
                }
            };
            this.log('adding local media stream if any');
            if (this._localStream) {
                if (!this._peerConnection.addTrack) {
                    this._peerConnection.addStream(this._localStream);
                    this.log('adding local media stream by stream');
                }
                else {
                    try {
                        this.log('adding local media stream by track');
                        this._localStream.getTracks().forEach(function (track) {
                            _this._peerConnection.addTrack(track, _this._localStream);
                        });
                    }
                    catch (e) {
                        this.log("error: ".concat(e), 'error');
                    }
                }
            }
            // Add an audio and video transceiver that are send and receive,
            // regardless of whether the user microphone / camera is currently
            // available.
            this._peerConnection.addTransceiver('audio', { direction: 'sendrecv' });
            this._peerConnection.addTransceiver('video', { direction: 'sendrecv' });
            // create updateOffer if resumeSessionId exists
            if (body.resumeSessionId) {
                var offerOptions = {
                    voiceActivityDetection: false,
                    iceRestart: true,
                };
                this._sessionId = body.resumeSessionId;
                this._isResumedSession = true;
                this.log("established, trying to resume session with session_id = ".concat(body.resumeSessionId));
                this.createOffer(this._peerConnection, offerOptions)
                    .then(function (sessionDescription) {
                    _this.createdDescription.bind(_this);
                    _this.createdDescription(sessionDescription, 'updateOffer');
                })
                    .catch(this._sessionError.bind(this));
            }
            else {
                // Create a webrtc offer
                var offerOptions = {
                    voiceActivityDetection: false,
                    iceRestart: false,
                };
                this._isResumedSession = false;
                this.createOffer(this._peerConnection, offerOptions)
                    .then(this.createdDescription.bind(this))
                    .catch(this._sessionError.bind(this));
            }
        }
        else if (name === 'accepted') {
            // accepted - DP is starting / forming webrtc connection
            this._connectionState.setConnectionState(ConnectionStateTypes_1.ConnectionStateTypes.ConnectingToDigitalPerson);
            this.log("accepted, session_id = ".concat(body.sessionId));
            this._sessionId = body.sessionId;
            this._resumeRequested = body.resumeRequested;
            this._server = body.server;
            this._sceneId = body.sceneId;
            // The session has been accepted, send any outgoing queued messages
            for (var i = 0; i < this._outgoingQueue.length; i++) {
                this._outgoingQueue[i].body.sessionId = this._sessionId;
                this.sendMessage(this._outgoingQueue[i]);
            }
            this._outgoingQueue = [];
            // Monitor for orientation change events to update the camera rotation
            var callback = function () {
                if (_this) {
                    _this.sendCameraRotation();
                }
            };
            window.addEventListener('orientationchange', callback);
            this._removeListeners.push({
                target: window,
                name: 'orientationchange',
                callback: callback,
            });
            this.sendCameraRotation();
            var view = document.defaultView || window;
            var style = view.getComputedStyle(this._videoElement);
            var video_width = parseInt("".concat(style.width), 10); // cs check changed frm this.videoElement
            var video_height = parseInt("".concat(style.height), 10);
            this.log("accepted, sending video width/height: ".concat(video_width, " / ").concat(video_height));
            this.sendVideoBounds(video_width, video_height);
            // Send all pending log messages
            this.sendlogMessage(this._pendingLog);
            this._pendingLog = [];
            // Check whether the the server needs us to route control messages to the
            // orchestration server.
            if (body.controlUrl) {
                this._controlUrl = body.controlUrl;
                this._controlQueue = [];
                this._controlOpen = false;
                this._controlConnection = new WebSocket(body.controlUrl + '?access_token=' + this._accessToken);
                this._controlConnection.onmessage = function (msg) {
                    var raw_text = msg.data;
                    if (raw_text) {
                        // forward this message to the session server
                        if (_this._serverConnection.readyState === WebSocket.OPEN) {
                            _this._serverConnection.send(raw_text);
                        }
                    }
                };
                this._controlConnection.onerror = function () {
                    _this.close(true, 'controlFailed', deferred);
                };
                // wait for the websocket to open, then continue with setup
                this._controlConnection.onopen = function (event) {
                    _this.log('control websocket open');
                    if (!_this._controlOpen) {
                        _this._controlOpen = true;
                        // send any pending orchestration/control messages in the order they were received
                        for (var i = 0; i < _this._controlQueue.length; i++) {
                            _this.log("control websocket now open, forwarding queued message: ".concat(_this._controlQueue[i]));
                            _this._controlConnection.send(_this._controlQueue[i]);
                        }
                        _this._controlQueue = [];
                    }
                };
                // setup a close handler
                this._controlConnection.onclose = function (event) {
                    _this.log("control closed: code(".concat(event.code, "), reason(").concat(event.reason, "), clean(").concat(event.wasClean, ")"));
                    _this.close(true, 'controlDisconnected', deferred);
                };
            }
        }
        else if (name === 'answer') {
            this.log('set remote description');
            this.log(JSON.stringify(body));
            var sessionDescription = {
                sdp: body.sdp,
                type: 'answer',
            };
            this.setRemoteDescription(this._peerConnection, sessionDescription)
                .then(function () {
                // Currently there's nothing to do
            })
                .catch(this._sessionError.bind(this));
        }
        else if (name === 'connected') {
            if (this._remoteStream) {
                // connected - DP is started and ready the webrtc session has connected
                this._connectionState.setConnectionState(ConnectionStateTypes_1.ConnectionStateTypes.Connected);
                this.onConnectedSuccess();
                if (deferred) {
                    deferred.resolve(body.sessionId);
                }
            }
            else {
                this.log('Connected but no remote media stream available');
                // The remote stream has not connected yet, give it more time to connect
                this._connectPendingRemoteStream = function () {
                    _this.onConnectedSuccess();
                    if (deferred) {
                        deferred.resolve(body.sessionId);
                    }
                };
            }
        }
        else if (name === 'ice') {
            this.log('add ice candidate');
            var addCandidate = void 0;
            if (body.complete) {
                if (this._features.isEdge) {
                    addCandidate = this._peerConnection.addIceCandidate(new RTCIceCandidate({
                        candidate: '',
                        sdpMid: '',
                        sdpMLineIndex: 0,
                    }));
                }
            }
            else {
                var iceCandidate = new RTCIceCandidate({
                    candidate: body.candidate,
                    sdpMid: body.sdpMid,
                    sdpMLineIndex: body.sdpMLineIndex,
                });
                addCandidate = this._peerConnection.addIceCandidate(iceCandidate);
            }
            if (addCandidate) {
                addCandidate.catch(this._sessionError.bind(this));
            }
        }
        else if (name === 'offer') {
            // NB: For calls inbound to browser, currently not used
            //     Perhaps we might use this for queueing to talk to an avatar?
            this._sessionId = body.sessionId;
            var sessionDescription = {
                sdp: body.sdp,
                type: 'offer',
            };
            this.setRemoteDescription(this._peerConnection, sessionDescription)
                // Create an answer in response to the offer
                .then(function () { return _this.createAnswer(_this._peerConnection); })
                .then(this.createdDescription.bind(this))
                .catch(this._sessionError.bind(this));
        }
        else if (name === 'userText') {
            this.log("rtc - user text message received: ".concat(body.userText));
            this._onUserText(body.userText);
        }
        else if (name === 'close') {
            this.close(false, body.reason, deferred);
        }
    };
    Session.prototype.gotIceCandidate = function (event) {
        if (event.candidate) {
            this.log('got local ice candidate');
            // Note we name each ice field as the IE/Safari plugin doesn't reflect these for json serialization
            this.sendRtcEvent('ice', {
                complete: false,
                candidate: event.candidate.candidate,
                sdpMid: event.candidate.sdpMid,
                sdpMLineIndex: event.candidate.sdpMLineIndex,
            });
        }
        else {
            this.log('end ice candidate');
            // all ice candidates have been gathered, send an end of ice notification
            this.sendRtcEvent('ice', {
                complete: true,
                candidate: '',
                sdpMid: '',
                sdpMLineIndex: 0,
            });
        }
    };
    Session.prototype.createdDescription = function (description, messageName) {
        var _this = this;
        if (messageName === void 0) { messageName = 'offer'; }
        this.log('got description');
        // Note we name each ice field as the IE/Safari plugin doesn't  reflect these for json serialization
        var descriptionObj = { sdp: description.sdp, type: description.type };
        this.log(JSON.stringify({ sdp: descriptionObj }));
        this.setLocalDescription(this._peerConnection, description)
            .then(function () {
            // Note with the sdp offer information we also send the
            // current video element width/height to remote end when
            // setting up webrtc session so that it can send the best
            // width/height
            _this.log('send sdp offer to server');
            // Note we name each sdp field as the IE/Safari plugin doesn't  reflect these for json serialization
            _this.sendRtcEvent(messageName, {
                sdp: _this._peerConnection.localDescription
                    ? _this._peerConnection.localDescription.sdp
                    : null,
                type: _this._peerConnection.localDescription
                    ? _this._peerConnection.localDescription.type
                    : null,
                user_text: _this._connectUserText,
                features: { videoStartedEvent: true },
            });
        })
            .catch(this._sessionError.bind(this));
    };
    Session.prototype.onRemoteStream = function (stream) {
        this.log('got remote stream');
        this._remoteStream = stream;
        this.log("ICE connection state: ".concat(this._peerConnection.iceConnectionState));
        if (this._connectPendingRemoteStream) {
            // A connect has been received however it has been paused while
            // we waited for the remote stream - continue it now
            this._connectPendingRemoteStream();
            this._connectPendingRemoteStream = null;
        }
    };
    Session.prototype.onConnectedSuccess = function () {
        var _this = this;
        var _a, _b;
        this._onConnected(this._resumeRequested, this._isResumedSession, this._server, this.sessionId);
        this._videoElement.hidden = false; // remote video stream
        this._videoElement.srcObject = this._remoteStream;
        var callback = function (event) { return tslib_1.__awaiter(_this, void 0, void 0, function () {
            return tslib_1.__generator(this, function (_a) {
                if (this._remoteStream) {
                    this._remoteStream.addTrack(event.track);
                }
                return [2 /*return*/];
            });
        }); };
        this._peerConnection.addEventListener('track', callback);
        this._removeListeners.push({
            target: this._peerConnection,
            name: 'track',
            callback: callback,
        });
        this.log('video enabled');
        // Update the server of the current camera active state
        this.sendUserCamera();
        // Update the application of the current microphone & camera state
        (_a = this._onMicrophoneActive) === null || _a === void 0 ? void 0 : _a.call(this.isMicrophoneActive());
        (_b = this._onCameraActive) === null || _b === void 0 ? void 0 : _b.call(this.isCameraActive());
    };
    Session.prototype.onVideoLoaded = function (e) {
        var _this = this;
        this.log('video has loaded');
        var videoStarted = function () {
            _this.log('video has started playing');
            _this.sendRtcEvent('videoStarted', {});
            _this.microphoneMuted = false; // allow the user to speak now that the DP is visible
        };
        // If the video element isn't muted the videoStarted event can be sent immediately
        if (!this._videoElement.muted) {
            videoStarted();
            return;
        }
        // The video element is muted, wait for it to be unmuted before declaring the video fully started
        // there isn't an event for unmuted however volumechange apparently provides a
        // fair alternative: https://stackoverflow.com/questions/25105414/html5-video-onmuted-and-onloop-event
        var unmuteCallback = function () {
            videoStarted();
            _this._videoElement.removeEventListener('volumechange', unmuteCallback);
        };
        this._videoElement.addEventListener('volumechange', unmuteCallback, false);
    };
    Session.prototype.sendRtcEvent = function (name, body) {
        if (this._serverConnection === null) {
            return;
        }
        if (this._sessionId) {
            body.sessionId = this._sessionId;
        }
        var payload = { category: 'webrtc', kind: 'event', name: name, body: body };
        if (this._sessionId || name === 'offer') {
            this.sendMessage(payload);
        }
        else {
            // The session has not yet been accepted, queue the message until it is
            this._outgoingQueue.push(payload);
        }
    };
    Session.prototype.sendVideoBounds = function (width, height) {
        this.sendRtcEvent('videoBounds', { width: width, height: height });
    };
    /**
     * Sends updated user camera rotation to server
     * this gives the app the chance to choose the required rotation of the user camera
     * such that it matches the devices orientation.  Values can be 0, 90, 180, 270.
     * @param rotation - The clockwise rotation in degrees of the user video feed (0, 90, 180 or 270)
     * @internal
     */
    Session.prototype.sendUserCamera = function (rotation) {
        var body = { active: this.isCameraActive() };
        if (rotation !== undefined) {
            body.rotation = rotation;
        }
        this.sendRtcEvent('userCamera', body);
    };
    Session.prototype.sendCameraRotation = function () {
        if (this._features.isIos) {
            var orientation_1 = window.orientation;
            this.log("send updated camera rotation, device orientation: ".concat(orientation_1));
            // Compute the camera orientation for iOS, degrees to rotate the image to the right
            // to give it a correct orientation relative to how the iOS device is held
            var rotateCamera = 0;
            // NB: iOS safari fixedCameraOrientation = -90; - iOS front camera orientation in terms of window orientation positions
            if (orientation_1 === 0) {
                rotateCamera = 90;
            }
            else if (orientation_1 === 90) {
                rotateCamera = 180;
            }
            else if (orientation_1 === 180) {
                rotateCamera = 270;
            }
            else if (orientation_1 === -90) {
                rotateCamera = 0;
            }
            this.sendUserCamera(rotateCamera);
        }
    };
    Session.prototype.sendMessage = function (message) {
        if (!this._serverConnection) {
            return;
        }
        if (this._serverConnection.readyState === WebSocket.OPEN) {
            // connected
            this._serverConnection.send(JSON.stringify(message));
        }
        else {
            this.log("server connection not ready, discarding message: ".concat(message));
        }
    };
    Session.prototype.sendUserText = function (text) {
        this.sendRtcEvent('userText', { userText: text });
    };
    Session.prototype.hasCamera = function (userMedia) {
        return (userMedia === scene_1.UserMedia.Camera ||
            userMedia === scene_1.UserMedia.MicrophoneAndCamera);
    };
    Session.prototype.hasMicrophone = function (userMedia) {
        return (userMedia === scene_1.UserMedia.Microphone ||
            userMedia === scene_1.UserMedia.MicrophoneAndCamera);
    };
    Session.prototype.makeUserMedia = function (microphone, webcam) {
        if (microphone && webcam) {
            return scene_1.UserMedia.MicrophoneAndCamera;
        }
        else if (microphone) {
            return scene_1.UserMedia.Microphone;
        }
        else if (webcam) {
            return scene_1.UserMedia.Camera;
        }
        return scene_1.UserMedia.None;
    };
    Session.prototype.findSenderTrackByKind = function (kind) {
        var e_3, _a;
        var _b;
        if (!this._peerConnection) {
            return null;
        }
        var senders = this._peerConnection.getSenders();
        try {
            for (var senders_1 = tslib_1.__values(senders), senders_1_1 = senders_1.next(); !senders_1_1.done; senders_1_1 = senders_1.next()) {
                var sender = senders_1_1.value;
                if (sender.track && ((_b = sender.track) === null || _b === void 0 ? void 0 : _b.kind) === kind) {
                    return sender.track;
                }
            }
        }
        catch (e_3_1) { e_3 = { error: e_3_1 }; }
        finally {
            try {
                if (senders_1_1 && !senders_1_1.done && (_a = senders_1.return)) _a.call(senders_1);
            }
            finally { if (e_3) throw e_3.error; }
        }
        return null;
    };
    Session.prototype.findSenderByKind = function (kind) {
        var e_4, _a, e_5, _b;
        var _c, _d;
        if (!this._peerConnection) {
            return null;
        }
        try {
            for (var _e = tslib_1.__values(this._peerConnection.getTransceivers()), _f = _e.next(); !_f.done; _f = _e.next()) {
                var transceiver = _f.value;
                if (transceiver.direction === 'sendrecv' &&
                    ((_d = (_c = transceiver.receiver) === null || _c === void 0 ? void 0 : _c.track) === null || _d === void 0 ? void 0 : _d.kind) === kind) {
                    return transceiver.sender;
                }
            }
        }
        catch (e_4_1) { e_4 = { error: e_4_1 }; }
        finally {
            try {
                if (_f && !_f.done && (_a = _e.return)) _a.call(_e);
            }
            finally { if (e_4) throw e_4.error; }
        }
        try {
            for (var _g = tslib_1.__values(this._peerConnection.getSenders()), _h = _g.next(); !_h.done; _h = _g.next()) {
                var sender = _h.value;
                if (sender.track === null || sender.track.kind === kind) {
                    return sender;
                }
            }
        }
        catch (e_5_1) { e_5 = { error: e_5_1 }; }
        finally {
            try {
                if (_h && !_h.done && (_b = _g.return)) _b.call(_g);
            }
            finally { if (e_5) throw e_5.error; }
        }
        return null;
    };
    Session.prototype.processChangeUserMediaQueue = function () {
        var _a, _b, _c, _d;
        return tslib_1.__awaiter(this, void 0, void 0, function () {
            var operation, lastMicrophoneActive, lastCameraActive, e_6;
            return tslib_1.__generator(this, function (_e) {
                switch (_e.label) {
                    case 0:
                        operation =
                            this._changeUserMediaQueue.length > 0
                                ? this._changeUserMediaQueue[0]
                                : undefined;
                        if (!operation) return [3 /*break*/, 5];
                        _e.label = 1;
                    case 1:
                        _e.trys.push([1, 3, , 4]);
                        lastMicrophoneActive = this.isMicrophoneActive();
                        lastCameraActive = this.isCameraActive();
                        // Change the media to that requested by the operation
                        return [4 /*yield*/, this.changeUserMediaInternal(this.makeUserMedia((_a = operation.microphone) !== null && _a !== void 0 ? _a : lastMicrophoneActive, (_b = operation.camera) !== null && _b !== void 0 ? _b : lastCameraActive))];
                    case 2:
                        // Change the media to that requested by the operation
                        _e.sent();
                        // Notify of any change of microphone state
                        if (operation.microphone !== undefined &&
                            operation.microphone !== lastMicrophoneActive) {
                            (_c = this._onMicrophoneActive) === null || _c === void 0 ? void 0 : _c.call(this.isMicrophoneActive());
                        }
                        // Notify of any change of camera state
                        if (operation.camera !== undefined &&
                            operation.camera !== lastCameraActive) {
                            (_d = this._onCameraActive) === null || _d === void 0 ? void 0 : _d.call(this.isCameraActive());
                        }
                        // The operation has completed successfully
                        operation.deferred.resolve();
                        return [3 /*break*/, 4];
                    case 3:
                        e_6 = _e.sent();
                        operation.deferred.reject(e_6);
                        return [3 /*break*/, 4];
                    case 4:
                        // Remove the operation as it's now finished
                        this._changeUserMediaQueue.shift();
                        _e.label = 5;
                    case 5:
                        if (operation) return [3 /*break*/, 0];
                        _e.label = 6;
                    case 6: return [2 /*return*/];
                }
            });
        });
    };
    Session.prototype.changeUserMediaInternal = function (newUserMedia) {
        return tslib_1.__awaiter(this, void 0, void 0, function () {
            var microphoneTrack, cameraTrack, needMicrophoneUpgrade, needCameraUpgrade, newMediaStream, requiredMedia, mediaDeferred;
            var _this = this;
            return tslib_1.__generator(this, function (_a) {
                switch (_a.label) {
                    case 0:
                        microphoneTrack = this.findSenderTrackByKind('audio');
                        cameraTrack = this.findSenderTrackByKind('video');
                        needMicrophoneUpgrade = this.hasMicrophone(newUserMedia) &&
                            (!microphoneTrack || microphoneTrack.readyState === 'ended');
                        needCameraUpgrade = this.hasCamera(newUserMedia) &&
                            (!cameraTrack || cameraTrack.readyState === 'ended');
                        newMediaStream = null;
                        if (!(needMicrophoneUpgrade || needCameraUpgrade)) return [3 /*break*/, 2];
                        requiredMedia = this.makeUserMedia(needMicrophoneUpgrade, needCameraUpgrade);
                        mediaDeferred = new Deferred_1.Deferred();
                        this.selectUserMedia(requiredMedia, requiredMedia, mediaDeferred, function (stream, deferred) { return tslib_1.__awaiter(_this, void 0, void 0, function () {
                            return tslib_1.__generator(this, function (_a) {
                                newMediaStream = stream;
                                deferred.resolve();
                                return [2 /*return*/];
                            });
                        }); });
                        return [4 /*yield*/, mediaDeferred.promise];
                    case 1:
                        _a.sent();
                        if (!this._localStream) {
                            this._localStream = new MediaStream();
                        }
                        _a.label = 2;
                    case 2: 
                    // Update the microphone track
                    return [4 /*yield*/, this.updateSenderTrack('audio', this.hasMicrophone(newUserMedia), newMediaStream)];
                    case 3:
                        // Update the microphone track
                        _a.sent();
                        // Update the camera track
                        return [4 /*yield*/, this.updateSenderTrack('video', this.hasCamera(newUserMedia), newMediaStream)];
                    case 4:
                        // Update the camera track
                        _a.sent();
                        // Update the server of the current camera active state
                        this.sendUserCamera();
                        return [2 /*return*/];
                }
            });
        });
    };
    // Update the RTP sender / track to the given active state. If active then the newMediaStream must
    // contain a track for the requested 'kind'
    Session.prototype.updateSenderTrack = function (kind, active, newMediaStream) {
        var _a, _b;
        return tslib_1.__awaiter(this, void 0, void 0, function () {
            var sender, track, newTrack, e_7;
            return tslib_1.__generator(this, function (_c) {
                switch (_c.label) {
                    case 0:
                        sender = this.findSenderByKind(kind);
                        track = sender === null || sender === void 0 ? void 0 : sender.track;
                        if (!(!!sender && (!track || active !== track.enabled))) return [3 /*break*/, 7];
                        this.log('new user ' + kind + ' active state = ' + active);
                        if (!active) return [3 /*break*/, 6];
                        _c.label = 1;
                    case 1:
                        _c.trys.push([1, 4, , 5]);
                        if (track) {
                            (_a = this._localStream) === null || _a === void 0 ? void 0 : _a.removeTrack(track);
                        }
                        if (!newMediaStream) return [3 /*break*/, 3];
                        newTrack = this.getTrackByKind(newMediaStream, kind);
                        if (!newTrack) return [3 /*break*/, 3];
                        (_b = this._localStream) === null || _b === void 0 ? void 0 : _b.addTrack(newTrack);
                        if (!(sender.track !== newTrack)) return [3 /*break*/, 3];
                        this.log('replacing user ' + kind + ' track');
                        return [4 /*yield*/, sender.replaceTrack(newTrack)];
                    case 2:
                        _c.sent();
                        _c.label = 3;
                    case 3: return [3 /*break*/, 5];
                    case 4:
                        e_7 = _c.sent();
                        this.log("failed to get user ".concat(kind, " track, error: ").concat(e_7), 'error');
                        throw (0, make_error_1.makeError)('failed to get user ' + kind + ': ' + e_7, 'failedUpgrade');
                    case 5: return [3 /*break*/, 7];
                    case 6:
                        if (track) {
                            track.enabled = false;
                            track.stop();
                        }
                        _c.label = 7;
                    case 7: return [2 /*return*/];
                }
            });
        });
    };
    Session.prototype.getTrackByKind = function (stream, kind) {
        var e_8, _a;
        if (stream) {
            try {
                for (var _b = tslib_1.__values(stream.getTracks()), _c = _b.next(); !_c.done; _c = _b.next()) {
                    var track = _c.value;
                    if (track.kind === kind) {
                        return track;
                    }
                }
            }
            catch (e_8_1) { e_8 = { error: e_8_1 }; }
            finally {
                try {
                    if (_c && !_c.done && (_a = _b.return)) _a.call(_b);
                }
                finally { if (e_8) throw e_8.error; }
            }
        }
        return undefined;
    };
    Session.prototype.isSenderTrackEnabled = function (kind) {
        var track = this.findSenderTrackByKind(kind);
        return Boolean(track === null || track === void 0 ? void 0 : track.enabled);
    };
    Session.prototype.isMicrophoneActive = function () {
        return this.isSenderTrackEnabled('audio');
    };
    Session.prototype.isCameraActive = function () {
        return this.isSenderTrackEnabled('video');
    };
    Session.prototype.setMediaDeviceActive = function (_a) {
        var microphone = _a.microphone, camera = _a.camera;
        return tslib_1.__awaiter(this, void 0, void 0, function () {
            var deferred;
            return tslib_1.__generator(this, function (_b) {
                deferred = new Deferred_1.Deferred();
                this._changeUserMediaQueue.push({ microphone: microphone, camera: camera, deferred: deferred });
                if (this._changeUserMediaQueue.length === 1) {
                    this.processChangeUserMediaQueue();
                }
                return [2 /*return*/, deferred.promise];
            });
        });
    };
    Session.prototype.close = function (sendRtcClose, reason, deferred) {
        var e_9, _a;
        if (sendRtcClose === void 0) { sendRtcClose = true; }
        if (reason === void 0) { reason = 'normal'; }
        if (this._closed) {
            return;
        }
        this._closed = true;
        if (this._peerConnection) {
            try {
                this._peerConnection.close();
            }
            catch (e) {
                this.log("error: ".concat(e), 'error');
            }
        }
        if (this._localStream) {
            try {
                var tracks = this._localStream.getTracks();
                for (var i in tracks) {
                    tracks[i].stop();
                }
            }
            catch (e) {
                this.log("error: ".concat(e), 'error');
            }
        }
        if (sendRtcClose) {
            this.sendRtcEvent('close', { reason: 'normal' });
        }
        if (deferred) {
            if (deferred.isResolved()) {
                this._onClose(reason);
            }
            else {
                deferred.reject((0, make_error_1.makeError)('websocket closed: ' + reason, reason));
            }
        }
        if (this._serverConnection) {
            this.log('closing server connection');
            this._serverConnection.close();
        }
        if (this._controlConnection) {
            this._controlConnection.close();
        }
        try {
            // Deregister event listeners
            for (var _b = tslib_1.__values(this._removeListeners), _c = _b.next(); !_c.done; _c = _b.next()) {
                var listener = _c.value;
                listener.target.removeEventListener(listener.name, listener.callback);
            }
        }
        catch (e_9_1) { e_9 = { error: e_9_1 }; }
        finally {
            try {
                if (_c && !_c.done && (_a = _b.return)) _a.call(_b);
            }
            finally { if (e_9) throw e_9.error; }
        }
    };
    Session.prototype.createOffer = function (peerConnection, options) {
        return peerConnection.createOffer(options);
    };
    Session.prototype.setRemoteDescription = function (peerConnection, sessionDescription) {
        return peerConnection.setRemoteDescription(sessionDescription);
    };
    Session.prototype.setLocalDescription = function (peerConnection, description) {
        return peerConnection.setLocalDescription(description);
    };
    Session.prototype.createAnswer = function (peerConnection) {
        return peerConnection.createAnswer();
    };
    Object.defineProperty(Session.prototype, "peerConnection", {
        get: function () {
            return this._peerConnection;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Session.prototype, "serverConnection", {
        get: function () {
            return this._serverConnection;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Session.prototype, "sessionId", {
        get: function () {
            return this._sessionId;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Session.prototype, "server", {
        get: function () {
            return this._server;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Session.prototype, "sceneId", {
        get: function () {
            return this._sceneId;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Session.prototype, "isMicrophoneConnected", {
        get: function () {
            return !!this.findSenderTrackByKind('audio');
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Session.prototype, "isCameraConnected", {
        get: function () {
            return !!this.findSenderTrackByKind('video');
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Session.prototype, "features", {
        get: function () {
            return this._features;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Session.prototype, "microphoneMuteDelay", {
        get: function () {
            return this._microphoneMuteDelay;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Session.prototype, "userMediaStream", {
        get: function () {
            return this._localStream;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Session.prototype, "microphoneMuted", {
        get: function () {
            if (!this._localStream) {
                return true;
            }
            var audioTracks = this._localStream.getAudioTracks();
            if (!audioTracks || audioTracks.length < 1) {
                return true;
            }
            return !audioTracks[0].enabled;
        },
        set: function (mute) {
            var _a, _b;
            if (!this._localStream) {
                return;
            }
            var audioTracks = this._localStream.getAudioTracks();
            if (!audioTracks || audioTracks.length < 1) {
                return;
            }
            var audioSender = this.findSenderByKind('audio');
            if (((_a = audioSender === null || audioSender === void 0 ? void 0 : audioSender.track) === null || _a === void 0 ? void 0 : _a.readyState) === 'live' &&
                audioSender.track === audioTracks[0]) {
                var enable = !mute;
                audioTracks[0].enabled = enable;
                this.log("microphone muted active notification: ".concat(enable));
                (_b = this._onMicrophoneActive) === null || _b === void 0 ? void 0 : _b.call(enable);
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Session.prototype, "webcamMuted", {
        get: function () {
            if (!this._localStream) {
                return true;
            }
            var videoTracks = this._localStream.getVideoTracks();
            if (!videoTracks || videoTracks.length < 1) {
                return true;
            }
            return !videoTracks[0].enabled;
        },
        set: function (mute) {
            var _a, _b;
            if (!this._localStream) {
                return;
            }
            var videoTracks = this._localStream.getVideoTracks();
            if (!videoTracks || videoTracks.length < 1) {
                return;
            }
            var videoSender = this.findSenderByKind('video');
            if (((_a = videoSender === null || videoSender === void 0 ? void 0 : videoSender.track) === null || _a === void 0 ? void 0 : _a.readyState) === 'live' &&
                videoSender.track === videoTracks[0]) {
                var enable = !mute;
                videoTracks[0].enabled = enable;
                (_b = this._onCameraActive) === null || _b === void 0 ? void 0 : _b.call(enable);
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Session.prototype, "offsetX", {
        get: function () {
            return 0;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Session.prototype, "offsetY", {
        get: function () {
            return 0;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Session.prototype, "microphoneActiveCallbacks", {
        set: function (callbacks) {
            this._onMicrophoneActive = callbacks;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Session.prototype, "cameraActiveCallbacks", {
        set: function (callbacks) {
            this._onCameraActive = callbacks;
        },
        enumerable: false,
        configurable: true
    });
    return Session;
}());
exports.Session = Session;
//# sourceMappingURL=Session.js.map